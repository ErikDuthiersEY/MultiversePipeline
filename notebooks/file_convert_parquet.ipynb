{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc52a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13e2fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: c:/Users/WJ724NE/OneDrive - EY/Documents/MultiversePipeline/datasets/raw/\n",
      "OUT_DIR: c:/Users/WJ724NE/OneDrive - EY/Documents/MultiversePipeline/datasets/processed/\n"
     ]
    }
   ],
   "source": [
    "# Dir\n",
    "\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "RAW_DIR = ROOT_DIR / \"datasets\" / \"raw\"\n",
    "OUT_DIR = ROOT_DIR / \"datasets\" / \"processed\"\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"RAW_DIR: {RAW_DIR.as_posix()}/\")\n",
    "print(f\"OUT_DIR: {OUT_DIR.as_posix()}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4275e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs encontrados: 7\n",
      " - Bias_Dataset_.csv\n",
      " - Hallucination.csv\n",
      " - Reasoning_Close.csv\n",
      " - Reasoning_Open.csv\n",
      " - Refusal_Correctness_.csv\n",
      " - Summarization.csv\n",
      " - Variation_sensitivity_with_typos.csv\n",
      "Éxito: Bias_Dataset_.csv (enc=utf-8, sep=',')\n",
      "OK: Bias_Dataset_.csv → Bias_Dataset_.parquet\n",
      "Éxito: Hallucination.csv (enc=utf-8, sep=',')\n",
      "OK: Hallucination.csv → Hallucination.parquet\n",
      "Éxito: Reasoning_Close.csv (enc=utf-8, sep=',')\n",
      "OK: Reasoning_Close.csv → Reasoning_Close.parquet\n",
      "Éxito: Reasoning_Open.csv (enc=utf-8, sep=',')\n",
      "OK: Reasoning_Open.csv → Reasoning_Open.parquet\n",
      "Éxito: Refusal_Correctness_.csv (enc=utf-8, sep=',')\n",
      "OK: Refusal_Correctness_.csv → Refusal_Correctness_.parquet\n",
      "Éxito: Summarization.csv (enc=utf-8, sep=',')\n",
      "OK: Summarization.csv → Summarization.parquet\n",
      "Éxito: Variation_sensitivity_with_typos.csv (enc=utf-8, sep=',')\n",
      "OK: Variation_sensitivity_with_typos.csv → Variation_sensitivity_with_typos.parquet\n",
      "\n",
      "Total Parquets: 7\n"
     ]
    }
   ],
   "source": [
    "csv_files = [p for p in RAW_DIR.rglob(\"*.csv\")]\n",
    "print(f\"CSVs encontrados: {len(csv_files)}\")\n",
    "for p in csv_files:\n",
    "    print(f\" - {p.name}\")\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSVs en {RAW_DIR}\")\n",
    "\n",
    "def read_csv_robust(path: Path) -> pd.DataFrame:\n",
    "    encodings = [\"utf-8\", \"utf-8-sig\", \"latin-1\", \"cp1252\"]\n",
    "    delimiters = [',', ';', '\\t']\n",
    "    last_err = None\n",
    "    \n",
    "    for enc in encodings:\n",
    "        for delim in delimiters:\n",
    "            try:\n",
    "                df = pd.read_csv(path, sep=delim, engine=\"python\", encoding=enc, quoting=0, on_bad_lines='warn')\n",
    "                print(f\"Éxito: {path.name} (enc={enc}, sep='{delim}')\")\n",
    "                if len(df.columns) < 3:\n",
    "                    raise ValueError(\"Demasiado pocas columnas detectadas\")\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                print(f\"Intento fallido: {path.name} (enc={enc}, sep='{delim}'): {e}\")\n",
    "    \n",
    "    # Fallback csv.reader con quoting apropiado\n",
    "    print(f\"Fallback para {path.name}\")\n",
    "    with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        reader = csv.reader(f, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        rows = list(reader)\n",
    "    if not rows:\n",
    "        raise ValueError(\"Archivo vacío\")\n",
    "    columns = [str(c).strip() for c in rows[0]]\n",
    "    data = [row for row in rows[1:] if len(row) == len(columns)]\n",
    "    if not data:\n",
    "        raise ValueError(\"Sin datos válidos\")\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['id', 'index']:  \n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Convertir a Parquet - sin cambios, pero ahora leerá correctamente\n",
    "def to_parquet(csv_path: Path, out_dir: Path) -> Path:\n",
    "    df = read_csv_robust(csv_path)\n",
    "    df.columns = [str(c).strip() for c in df.columns]  \n",
    "    stem = csv_path.stem\n",
    "    pq_path = out_dir / f\"{stem}.parquet\"\n",
    "    df.to_parquet(pq_path, index=False)\n",
    "    return pq_path\n",
    "\n",
    "# Procesar\n",
    "parquet_paths = []\n",
    "for csv in csv_files:\n",
    "    try:\n",
    "        pq = to_parquet(csv, OUT_DIR)\n",
    "        parquet_paths.append(pq)\n",
    "        print(f\"OK: {csv.name} → {pq.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en {csv.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal Parquets: {len(parquet_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c4680",
   "metadata": {},
   "source": [
    "Auditoría de métricas [Despues se eliminara]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c492126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DEEPEVAL_DISABLE_ANALYTICS\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b03ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepEval telemetry disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "import requests as _requests\n",
    "\n",
    "\n",
    "os.environ[\"DEEPEVAL_HOME\"] = \"/does/not/exist\"\n",
    "os.environ[\"DEEPEVAL_DISABLE_ANALYTICS\"] = \"true\"\n",
    "\n",
    "\n",
    "fake_analytics = types.ModuleType(\"deepeval.analytics\")\n",
    "\n",
    "def no_op(*args, **kwargs):\n",
    "    return None\n",
    "\n",
    "fake_analytics.upload = no_op\n",
    "fake_analytics.log = no_op\n",
    "fake_analytics.posthog = no_op\n",
    "\n",
    "sys.modules[\"deepeval.analytics\"] = fake_analytics\n",
    "\n",
    "_original_post = _requests.post\n",
    "def block_posthog(url, *args, **kwargs):\n",
    "    if \"posthog\" in url:\n",
    "        return None\n",
    "    return _original_post(url, *args, **kwargs)\n",
    "\n",
    "_requests.post = block_posthog\n",
    "\n",
    "print(\"DeepEval telemetry disabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fc4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ExactMatchMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94056500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def compute_exact_match(predictions, references, use_deepeval=True):\n",
    "    \n",
    "    # ==========================\n",
    "    # Normalización mejorada\n",
    "    # ==========================\n",
    "    def normalize(s: str) -> str:\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        \n",
    "        # 1. Pasar todo a str por si es None o numérico\n",
    "        s = str(s)\n",
    "        \n",
    "        # 2. Normalizar Unicode (añade consistencia)\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "        \n",
    "        # 3. Pasar a minúsculas\n",
    "        s = s.lower()\n",
    "        \n",
    "        # 4. Quitar acentos (diacríticos)\n",
    "        s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "        \n",
    "        # 5. Reemplazar saltos de línea por espacios\n",
    "        s = s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        \n",
    "        # 6. Eliminar puntuación\n",
    "        s = \"\".join(c for c in s if c not in string.punctuation)\n",
    "        \n",
    "        # 7. Quitar espacios múltiples\n",
    "        s = \" \".join(s.split())\n",
    "        \n",
    "        return s\n",
    "    \n",
    "\n",
    "    # ==========================\n",
    "    # Opción DeepEval\n",
    "    # ==========================\n",
    "    if use_deepeval:\n",
    "        scores = []\n",
    "        \n",
    "        for pred, ref in zip(predictions, references):\n",
    "            metric = ExactMatchMetric(threshold=1.0)\n",
    "            \n",
    "            pred_norm = normalize(pred)\n",
    "            ref_norm  = normalize(ref)\n",
    "\n",
    "            tc = LLMTestCase(\n",
    "                input=\"\",\n",
    "                actual_output=pred_norm,\n",
    "                expected_output=ref_norm\n",
    "            )\n",
    "            \n",
    "            metric.measure(tc)\n",
    "            scores.append(metric.score)\n",
    "\n",
    "        return scores\n",
    "\n",
    "    # ==========================\n",
    "    # Fallback mejorado (sin DeepEval)\n",
    "    # ==========================\n",
    "    else:\n",
    "        out = []\n",
    "        for p, r in zip(predictions, references):\n",
    "            p_norm = normalize(p)\n",
    "            r_norm = normalize(r)\n",
    "            out.append(1.0 if p_norm == r_norm else 0.0)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ebcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "from deepeval.metrics import ExactMatchMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "def compute_exact_match(predictions, references):\n",
    "    \"\"\"\n",
    "    Exact Match usando únicamente DeepEval,\n",
    "    pero con normalización avanzada para evitar fallos por:\n",
    "    - mayúsculas/minúsculas\n",
    "    - acentos\n",
    "    - puntuación\n",
    "    - saltos de línea\n",
    "    - espacios múltiples\n",
    "    - unicode inconsistente\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize(s: str) -> str:\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        \n",
    "        s = str(s)\n",
    "\n",
    "        # Normalizar unicode (muy importante para casos como \"mañana\")\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "\n",
    "        # Minúsculas\n",
    "        s = s.lower()\n",
    "\n",
    "        # Quitar acentos (diacríticos)\n",
    "        s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "\n",
    "        # Sustituir saltos de línea por espacios\n",
    "        s = s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "        # Eliminar toda puntuación\n",
    "        s = \"\".join(c for c in s if c not in string.punctuation)\n",
    "\n",
    "        # Eliminar espacios múltiples\n",
    "        s = \" \".join(s.split())\n",
    "\n",
    "        return s\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for pred, ref in zip(predictions, references):\n",
    "\n",
    "        pred_norm = normalize(pred)\n",
    "        ref_norm  = normalize(ref)\n",
    "\n",
    "        metric = ExactMatchMetric(threshold=1.0)\n",
    "\n",
    "        tc = LLMTestCase(\n",
    "            input=\"\",\n",
    "            actual_output=pred_norm,\n",
    "            expected_output=ref_norm\n",
    "        )\n",
    "\n",
    "        metric.measure(tc)\n",
    "        scores.append(metric.score) \n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749946cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error uploading: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)')))\n",
      "error uploading: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)')))\n"
     ]
    }
   ],
   "source": [
    "compute_exact_match([\"La pelota es  de color verde\"], [\"La pelota es de color roja\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2d3b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_exact_match([\"Hola mundo!\"], [\"Hola mundo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06c54b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error uploading: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)')))\n"
     ]
    }
   ],
   "source": [
    "# min mayus\n",
    "\n",
    "compute_exact_match([\"hola mundo\"], [\"Hola mundo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198eae1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>reasoning_open_avg</th>\n",
       "      <th>reasoning_open_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.407954</td>\n",
       "      <td>0.158733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  reasoning_open_avg  reasoning_open_delta\n",
       "0  o4-mini            0.407954              0.158733"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura del archivo output \n",
    "\n",
    "read = pd.read_parquet(r'C:\\Users\\WJ724NE\\OneDrive - EY\\Documents\\MultiversePipeline\\outputs\\obj_scores.parquet')\n",
    "read.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f67300",
   "metadata": {},
   "source": [
    "Test parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45ce49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_PATH = OUT_DIR / \"Reasoning_open.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2fbf022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Explain why the sky appears blue.</td>\n",
       "      <td>The sky appears blue because molecules in the ...</td>\n",
       "      <td>scientific_explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Describe how photosynthesis works in simple te...</td>\n",
       "      <td>Photosynthesis allows plants to convert sunlig...</td>\n",
       "      <td>scientific_explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Why do people form social groups?</td>\n",
       "      <td>People form social groups for support, coopera...</td>\n",
       "      <td>social_reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Explain the importance of critical thinking.</td>\n",
       "      <td>Critical thinking helps individuals evaluate i...</td>\n",
       "      <td>reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Why is exercise beneficial for mental health?</td>\n",
       "      <td>Exercise releases endorphins, reduces stress h...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Describe the nitrogen cycle.</td>\n",
       "      <td>The nitrogen cycle converts nitrogen between f...</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Why is global trade beneficial?</td>\n",
       "      <td>Global trade fosters economic growth, cultural...</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Explain how AI learns from data.</td>\n",
       "      <td>AI learns from data using algorithms to identi...</td>\n",
       "      <td>technical_explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Describe the effects of ocean currents on clim...</td>\n",
       "      <td>Ocean currents distribute heat, influence weat...</td>\n",
       "      <td>environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Why is curiosity a driver of discovery?</td>\n",
       "      <td>Curiosity motivates exploration, questions ass...</td>\n",
       "      <td>reasoning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                             prompt  \\\n",
       "0     1                  Explain why the sky appears blue.   \n",
       "1     2  Describe how photosynthesis works in simple te...   \n",
       "2     3                  Why do people form social groups?   \n",
       "3     4       Explain the importance of critical thinking.   \n",
       "4     5      Why is exercise beneficial for mental health?   \n",
       "..  ...                                                ...   \n",
       "95   96                       Describe the nitrogen cycle.   \n",
       "96   97                    Why is global trade beneficial?   \n",
       "97   98                   Explain how AI learns from data.   \n",
       "98   99  Describe the effects of ocean currents on clim...   \n",
       "99  100            Why is curiosity a driver of discovery?   \n",
       "\n",
       "                                     reference_answer                category  \n",
       "0   The sky appears blue because molecules in the ...  scientific_explanation  \n",
       "1   Photosynthesis allows plants to convert sunlig...  scientific_explanation  \n",
       "2   People form social groups for support, coopera...        social_reasoning  \n",
       "3   Critical thinking helps individuals evaluate i...               reasoning  \n",
       "4   Exercise releases endorphins, reduces stress h...                  health  \n",
       "..                                                ...                     ...  \n",
       "95  The nitrogen cycle converts nitrogen between f...                 biology  \n",
       "96  Global trade fosters economic growth, cultural...               economics  \n",
       "97  AI learns from data using algorithms to identi...   technical_explanation  \n",
       "98  Ocean currents distribute heat, influence weat...             environment  \n",
       "99  Curiosity motivates exploration, questions ass...               reasoning  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read = pd.read_parquet(PARQUET_PATH)\n",
    "read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
