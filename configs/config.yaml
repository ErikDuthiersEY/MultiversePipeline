run_name: "eval-v1"

global:
  dataset_version: "v1"
  base_model_id: "o4-mini" 
  compressed_model_id: "" 

inference:
  model_id: "o4-mini"
  azure_endpoint: "https://openai-eygpt.openai.azure.com/"
  azure_api_key: ""
  azure_api_version: "2024-12-01-preview"
  temperature: 0.0
  max_tokens: 2000
  n_workers: 6
  qps_limit: 2
  timeout_s: 90
  sample_size_per_task: 5


rule_based_metrics:
  tasks:
    - reasoning_closed
    - reasoning_open
    - summarization
    - sensitivity_variations
  dataset_files:
    reasoning_closed: "reasoning_close.parquet"
    reasoning_open: "reasoning_open.parquet"
    summarization: "summarization.parquet"
    sensitivity_variations: "variation_sensivity_with_typos.parquet"
  column_mapping:
    reasoning_closed:
      gold_answer: "reference"
    reasoning_open:
      reference_answer: "reference"
    summarization:
      reference_summary: "reference"
    sensitivity_variations: { }
  required_columns:
    reasoning_closed: ["id", "reference"]
    reasoning_open: ["id", "reference"]
    summarization: ["id", "reference"]
    sensitivity_variations: ["id", "prompt_original", "prompt_paraphrase", "prompt_typo_variant"]
  rouge_n: 2
  compute_averages: true
  use_deepeval: true
  verbose_mode: true
  hash: "auto"
  run_name: "multiverse-rule-metrics-multi"
  description: "Rule-based metrics for multiple models"

llm_evaluated_metrics:
  judge_model_id: "o4-mini"  
  azure_api_key: ""
  azure_endpoint: "https://openai-eygpt.openai.azure.com/"
  azure_api_version: "2024-12-01-preview"
  timeout_s: 120

  # Nombres de las tareas en raw_output.parquet
  bias_task_name: "bias_dataset"
  hallucination_task_name: "hallucination"