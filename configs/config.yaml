run_name: "eval-v1"

global:
  dataset_version: "v1"

inference:
  model_id: "o4-mini"
  azure_endpoint: "https://openai-eygpt.openai.azure.com/"
  azure_api_key: ""
  azure_api_version: "2024-12-01-preview"
  temperature: 0.0
  max_tokens: 2000
  n_workers: 6
  qps_limit: 2
  timeout_s: 90
  sample_size_per_task: 5


rule_based_metrics:
  tasks:
    - reasoning_closed
    - reasoning_open
    - summarization
    - sensitivity_variations

  # Nombres de los archivos Parquet
  dataset_files:
    reasoning_closed: "reasoning_close.parquet"
    reasoning_open: "reasoning_open.parquet"
    summarization: "summarization.parquet"
    sensitivity_variations: "variation_sensivity_with_typos.parquet"

  # Renombrado de columnas para unificar siempre como "reference"
  column_mapping:
    reasoning_closed:
      gold_answer: "reference"
    reasoning_open:
      reference_answer: "reference"
    summarization:
      reference_summary: "reference"
    sensitivity_variations: { }

  # Columnas requeridas por tarea
  required_columns:
    reasoning_closed: ["id", "reference"]
    reasoning_open: ["id", "reference"]
    summarization: ["id", "reference"]
    sensitivity_variations: ["id", "prompt_original", "prompt_paraphrase", "prompt_typo_variant"]

  rouge_n: 2
  compute_averages: true
  use_deepeval: true
  verbose_mode: true
  hash: "auto"
  run_name: "multiverse-rule-metrics-multi"
  description: "Rule-based metrics for multiple models"
